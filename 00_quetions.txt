Вопрос следующий: " Можно ли как-то посмотреть на сколько блоков был разбит 
некоторый большой файл на Datanode's, а также, где реплики для каждого 
блока файла хранятся ? ( информацию о метаданных хранит NameNode )".

Все это вы можете посмотреть с помощью команды: $hadoop fsck <file> -files -blocks -locations

Собственные заметки:

1) В чем основное отличие реляционных БД от Hadoop?

Hadoop способен решать задачи:
+
  горизонтальная масштабируемость за счёт дешевого железа
  отказоустойчивость
    репликация данных ( по умолчанию 3 уровня)
    перезапуск задач
  распределенные вычисления на кластере из множества машин
    скрывает сложности распределенных систем
    освобождает разработчиков от проблем системного уровня
      передача данных
      доставка кода к данным и др.
    последовательный доступ к данным
  поддержка принципа типа "один раз записать данные и много раз считывать в дальнейшем"
  подходи для хранения большого объёма данных
-
  данные дописываются только в конец файла
  не подходит для быстрого доступа к данных ( решено с помощью Hbase)

Реляционные БД решают задачи
-
  вертикальная масшабируемость за счёт апгрейда железа
    сложности при быстром росте нагрузки на БД
  сложности при решении задач распределенных вычислений из-за реляционного подхода
  проблема с хранением иерархических данных
  проблема при большом количестве столбцов ( но иногда используют компрессию по данным)
+
  поддержка ACID (контроль за целостность данных) и отсюда
    атомарность ( гарантия завершенности транзакции )
    согласованность ( гарантия согласованного состояния данных при изменении)
    изолированность ( гарантия того, что одна транзакция не влияет на результат выполнения другой)
      уровни изоляции (...)
    надежность (гарантия сохранения данных на диск)
  одновременный доступ к данным
  повышенная безопасность за счет нормализации и внешних ключей
  доступ к данным посредством SQL
  подходит для транзакционных систем
    быстрого доступа к данным

2) Объясните различия между HBase и Hive?

  Hbase - column-based (разяженная матрица), поддержка последовательного и произвольного чтения
+
  поддержка различных структур данных
  меньшая согласованность данных
  горизонтальная масштабируемость
  нет фиксированной струтуры колонок
  выборка значений по ключу
-
  нет поддержки SQL
  нет поддержки реляционной модели данных

Hive - DWH с поддержкой SQL
+
  поддержка структурированных данных
  предоставляет доступ к данным из HDFS и Hbase
-
  небольшие запросы могут занять длительное время

3) Как происходит удаление строк в HBase?

   Как такового удаления не происходит, данные помечаются "маркерами" delete и не учитываются при фильтрации в дальнейшем.

4) Есть ли какие-то проблемы с маленькими файлами в HDFS?

     Лучше хранить большие файлы, чем маленькие, потому что Datanode хранит информацию о файловом пространстве, 
     метаданных,расположении блоков данных в ОП. Если будет очень много маленьких файлов, то ресурсы для Datanode 
     нужно будет увеличить, также возрастет нагрузка при чтении данных с диска.

5) Как вы отлаживаете код на Hadoop?

     Есть несколько способов отладки:

     1) логирование
          самый простой писать логи выполнения шагов в output 
            вызов System.out.println (java) или же print(...) (python)
              этот способ часто использовал 
          использовать готовый класс-логгер в java (log4j), но не во всех случаях, 
          т.к. объём лог-файла может быть большим, поскольку в него пишется много отладочной информации
      2) использование счётчиков
          не пользовался

6) Как исключить несколько нод из кластера?

   Можно просто выключить их. Система должна корректно обработать данную ситуацию, при необходимости 
   еще можно запустить ребалансировку блоков данных по кластеру и оставшимся нодам.
   Убрать ноды из соответствующего конфига, но этого никогда не делал.


7) Как использую командную строку Linux просмотреть список всех выполняющихся задания на кластере Hadoop? Как убить задание?

    Через веб-интерфейс jobtracker самой простой, а конкретную команду ... 


8) Как реализовано индексирование в HDFS?

  В момент добавления данных в HDFS происходит их индексирование и в дальнейшем datanode знает, где \ куда обращаться за данными.


9) Что такое RowKey в HBase?

  По RowKey осуществляется поиск данных ... своего рода аналог primary key в таблице

10) Что такое JobTracker?

    Управляет запуском задач и определяет, на каком TaskTracker'е будет 
запущен worker и на каких данных, а также мониторит прогресс выполнения и перезапускает Tasks, если они по какой-то причине не выполнились или висят долгое время

